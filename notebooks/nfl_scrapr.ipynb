{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu-MfQlHpoRn",
        "outputId": "2b0733dc-feb3-4dcb-cd3c-abe86764be3e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import psycopg2 \n",
        "\n",
        "sys.path.append('../')\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "from db_utils import create_table, populate_table, insert_into_table\n",
        "from pbp_utils import (get_qb_pass, get_game_results, get_receiving, get_rushing,\n",
        "                       get_team_pass_yds, get_team_rush_yds, get_opp_pass,\n",
        "                       get_def_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# loading up the postgres credentials in a separate file. we could use environment variables\n",
        "# but doing it this way to mix it up!\n",
        "\n",
        "with open('../env.txt', 'r') as file:\n",
        "    env = file.read().splitlines()\n",
        "    user = env[0]\n",
        "    password = env[1]\n",
        "    host = env[2]\n",
        "    database = env[3]\n",
        "    port = env[4]\n",
        "    \n",
        "\n",
        "URI = f'postgresql://{user}:{password}@{host}:{port}/{database}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_dkD_JqY95",
        "outputId": "57bcfda7-0a1d-4d0a-f0dc-9e8505d2b178"
      },
      "outputs": [],
      "source": [
        "# gettin the directory path\n",
        "current_dir = os.getcwd()\n",
        "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
        "nfl_pbp_dir = 'data/pbp'\n",
        "nfl_depth_chart_dir = 'data/depth_charts'\n",
        "\n",
        "# loading all of the parquets files at once using the directory path\n",
        "# replacing backslashes with empty strings to avoid csv errors\n",
        "df = pd.read_parquet(f'{parent_dir}/{nfl_pbp_dir}')\n",
        "df['desc'] = df['desc'].str.replace('\\\\', '', regex=True)\n",
        "df['season'] = [int(x.split('_')[0]) for x in df.game_id]\n",
        "\n",
        "print(\"the shape of the pbp df is:\", df.shape)\n",
        "print(\"the memory usage of the pbp df is :\", df.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
        "\n",
        "# dropping columns to reduce the memory required in the hopes of populating the db\n",
        "# all at once, but it didn't work. I'll have to do it in chunks.\n",
        "unneeded_cols = ['nfl_api_id', 'old_game_id', 'home_coach', 'away_coach', 'game_stadium', 'weather']\n",
        "df.drop(columns=[x for x in df.columns if 'lateral' in x], inplace=True)\n",
        "df.drop(columns=[x for x in df.columns if 'player_2' in x], inplace=True)\n",
        "df.drop(columns=[x for x in df.columns if 'total' in x], inplace=True)\n",
        "df.drop(columns=unneeded_cols, inplace=True)\n",
        "\n",
        "print(\"the memory usage of the pbp after dropping is :\", df.memory_usage(deep=True).sum() / 1024**2, \"MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# creating the pbp table\n",
        "create_table(df=df, table_name='pbp', URI=URI)\n",
        "\n",
        "# creating a subset of the pbp df to test the populate_table function\n",
        "testdf = df.iloc[:10000]\n",
        "populate_table(df=testdf, table_name='pbp', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# using the insert function to get the pbp  into the database\n",
        "# quickly - estimated time with 50k chunksize is 2.5 minutes\n",
        "# the print statements keep track of the progress and \n",
        "# enable error identification\n",
        "\n",
        "chunks = [x for x in range(10000, len(df), 50000)]\n",
        "\n",
        "for i in range(len(chunks)):\n",
        "    \n",
        "    if i < (len(chunks) - 1):\n",
        "        print(i)\n",
        "        df_ = df.iloc[chunks[i] : chunks[i+1]].copy()\n",
        "        print(\"chunk final index:\", df_.index[-1])\n",
        "        try:\n",
        "            insert_into_table(df=df_, table_name='pbp', URI=URI)\n",
        "        except:\n",
        "            print(\"error in insert\", i)\n",
        "            print(df_.index[-1])\n",
        "            continue\n",
        "    else:\n",
        "        print(i)\n",
        "        df_ = df.iloc[chunks[i]:].copy()\n",
        "        print(\"last chunk final index:\", df_.index[-1])\n",
        "        try:\n",
        "            insert_into_table(df=df_, table_name='pbp', URI=URI)\n",
        "        except:\n",
        "            print(\"error for some other reason\", i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "depth_charts = pd.read_parquet(f'{parent_dir}/{nfl_depth_chart_dir}')\n",
        "depth_charts['depth_position'] = depth_charts['depth_position'].str.replace(\"\\n\", '')\n",
        "\n",
        "create_table(df=depth_charts, table_name='depth_charts', URI=URI)\n",
        "populate_table(df=depth_charts, table_name='depth_charts', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "player_stats = pd.read_parquet(f'{parent_dir}/data/player_stats')\n",
        "\n",
        "create_table(df=player_stats, table_name='player_stats', URI=URI)\n",
        "populate_table(df=player_stats, table_name='player_stats', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nextgen = pd.read_parquet(f'{parent_dir}/data/nextgen')\n",
        "\n",
        "create_table(df=nextgen, table_name='nextgen', URI=URI)\n",
        "populate_table(df=nextgen, table_name='nextgen', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "misc = pd.read_parquet(f'{parent_dir}/data/misc')\n",
        "\n",
        "create_table(df=misc, table_name='misc', URI=URI)\n",
        "populate_table(df=misc, table_name='misc', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snaps = pd.read_parquet(f'{parent_dir}/data/snap_counts')\n",
        "\n",
        "create_table(df=snaps, table_name='snaps', URI=URI)\n",
        "populate_table(df=snaps, table_name='snaps', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSC_e52GPwn7"
      },
      "outputs": [],
      "source": [
        "lee_sharpe = 'https://raw.githubusercontent.com/nflverse/nfldata/master/data/games.csv'\n",
        "\n",
        "ls_cols = ['game_id', 'overtime', 'home_rest', 'away_rest', 'div_game','roof', \n",
        "           'surface', 'temp', 'wind', 'home_coach', 'away_coach', 'referee']\n",
        "\n",
        "ls = pd.read_csv(lee_sharpe, usecols=ls_cols)\n",
        "ls = ls.sort_values(by='game_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_table(df=ls, table_name='lee_sharpe', URI=URI)\n",
        "populate_table(df=ls, table_name='lee_sharpe', URI=URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OTZX70GkVwE"
      },
      "outputs": [],
      "source": [
        "df['year'] = pd.to_datetime(df['game_date']).dt.year\n",
        "df['two_point_conv_result'] = (\n",
        "    df['two_point_conv_result']\n",
        "    .map(\n",
        "        {'success' : 1,\n",
        "         'failure' : 0,\n",
        "         }\n",
        "    )\n",
        "    .fillna('None')\n",
        ")\n",
        "\n",
        "df['game_date'] = pd.to_datetime(df['game_date'])\n",
        "df['spread_line'] = df['spread_line'] * -1\n",
        "df['field_goal_result'] = np.where(df['field_goal_result'] == 'made', 1, 0)\n",
        "df['time_between'] = df.groupby(['game_id'])['game_seconds_remaining'].transform(lambda x: x.sub(x.shift(-1)).fillna(0))\n",
        "df['play_type'] = np.where(df['two_point_attempt'] > 0.5, 'two_point_att', df['play_type'])\n",
        "df['air_yards_to_sticks'] = df['air_yards'].sub(df['ydstogo'])\n",
        "df['season'] = [int(x.split('_')[0]) for x in df.game_id]\n",
        "df['blocked_player_name'] = np.where(df['blocked_player_name'].notnull(), 1, 0)\n",
        "df['fg_0_39'] = np.where(((df['play_type'] == 'field_goal') & (df['kick_distance'].between(0,39))), 1, 0)\n",
        "df['fg_40_49'] = np.where(((df['play_type'] == 'field_goal') & (df['kick_distance'].between(40,49))), 1, 0)\n",
        "df['fg_50_on'] = np.where(((df['play_type'] == 'field_goal') & (df['kick_distance'].between(50,100))), 1, 0)\n",
        "df['extra_point_result'] = np.where(df['extra_point_result'] == 'good', 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEk1xEoVrjOV"
      },
      "outputs": [],
      "source": [
        "success = []\n",
        "\n",
        "for a, b, c in zip(df['down'], df['ydstogo'], df['yards_gained']):\n",
        "  frac = 0.4 * b\n",
        "  \n",
        "  if b == 0.0:\n",
        "    success.append(np.nan)\n",
        "  \n",
        "  elif ((a==1) | (a==2)):\n",
        "    if c >= frac:\n",
        "      success.append(1)\n",
        "    else:\n",
        "      success.append(0)\n",
        "  elif ((a==3) | (a==4)):\n",
        "    if c >= b:\n",
        "      success.append(1)\n",
        "    else:\n",
        "      success.append(0)\n",
        "\n",
        "df['success'] = success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdQVTfsCarfx"
      },
      "outputs": [],
      "source": [
        "def get_opp_pass(df=df):\n",
        "\n",
        "  opp_pass = (\n",
        "      df[df['pass_attempt'] == 1]\n",
        "      .groupby(['game_id', 'defteam'], as_index=False)['yards_gained']\n",
        "      .sum()\n",
        "      .rename(columns={'defteam' : 'team',\n",
        "                      'yards_gained' : 'opp_pass_yds'})\n",
        "  )\n",
        "\n",
        "  return opp_pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gmXQiUcbEwV"
      },
      "outputs": [],
      "source": [
        "def get_opp_rush(df=df):\n",
        "\n",
        "  opp_rush = (\n",
        "      df[df['rush_attempt'] == 1]\n",
        "      .groupby(['game_id', 'defteam'], as_index=False)['yards_gained']\n",
        "      .sum()\n",
        "      .rename(columns={'defteam' : 'team',\n",
        "                      'yards_gained' : 'opp_rush_yds'})\n",
        "  )\n",
        "\n",
        "  return opp_rush"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nm4RS8sJnHV7"
      },
      "outputs": [],
      "source": [
        "def get_def_stats(df=df):\n",
        "\n",
        "  def_cols = ['interception', 'season', 'return_touchdown', 'fumble', \n",
        "              'sack', 'epa']\n",
        "\n",
        "  def_stats = (\n",
        "      df[~df['desc'].str.contains('Aborted')].copy()\n",
        "      .groupby(['game_id', 'defteam'], as_index=False)\n",
        "      .agg({\n",
        "          'interception' : 'sum',\n",
        "          'season' : lambda x: x.unique()[0],\n",
        "          'return_touchdown' : 'sum',\n",
        "          'fumble_lost' : 'sum',\n",
        "          'sack' : 'sum',\n",
        "          'safety' : 'sum',\n",
        "          'blocked_player_name' : 'sum'\n",
        "      })\n",
        "      .rename(columns={\n",
        "          'defteam' : 'team',\n",
        "          'interception' : 'def_int',\n",
        "          'return_touchdown' : 'def_td',\n",
        "          'sack' : 'def_sack',\n",
        "          'fumble' : 'def_fumble',\n",
        "          'blocked_player_name' : 'kick_blocked'})\n",
        "  )\n",
        "  \n",
        "  return def_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lESwft1k9zEd"
      },
      "outputs": [],
      "source": [
        "kicker_df = get_kicker_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugiq_2Mf1xMa"
      },
      "outputs": [],
      "source": [
        "def create_ref_dict():\n",
        "\n",
        "  names = games_df['referee'].unique()\n",
        "  ref_dict = {}\n",
        "\n",
        "  for i in range(len(names)-1):\n",
        "    sim = process.extractOne(names[i], names[i+1:])\n",
        "    \n",
        "    if sim[1] > 85:\n",
        "      ref_dict[names[i]] = sim[0]\n",
        "\n",
        "  # del ref_dict['Jim Sprenger']\n",
        "  ref_rev_dict = {y : x  for x, y in ref_dict.items()}\n",
        "\n",
        "  return ref_rev_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh9tUUyMp9Nk"
      },
      "outputs": [],
      "source": [
        "def get_rolling_qb_epa(df=df):\n",
        "\n",
        "  qb_epa_dropback = df[df['qb_dropback'] == 1][['game_id', 'passer_player_name', 'epa', 'wp']].copy()\n",
        "  qb_epa_db = qb_epa_dropback[qb_epa_dropback['passer_player_name'].notnull()].copy()\n",
        "  qb_epa_db.replace('Jos.Allen', 'J.Allen', inplace=True)\n",
        "  qb_epa_db['1000_rolling_mean'] = qb_epa_db.groupby('passer_player_name')['epa'].transform(lambda x: x.shift().rolling(1000, min_periods=200).mean())\n",
        "  qb_epa_db['exp_career_mean'] = qb_epa_db.groupby('passer_player_name')['epa'].transform(lambda x: x.shift().expanding().mean())\n",
        "\n",
        "  return qb_epa_db.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sKDuteHbDD7"
      },
      "outputs": [],
      "source": [
        "# getting red zone statistics\n",
        "\n",
        "rz_df = df[df['yardline_100'] <= 20].copy()\n",
        "\n",
        "rz_rushing = get_rushing(df=rz_df)\n",
        "rz_receiving = get_receiving(df=rz_df)\n",
        "rz_qbs = get_qb_pass(df=rz_df)\n",
        "\n",
        "rz_qbs = (\n",
        "    rz_qbs\n",
        "    .merge(rz_rushing.drop(columns='success'), how='left', on=['game_id', 'player', 'player_id', 'team', 'total_line', 'home_team', 'away_team'])\n",
        "    .fillna(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuDFitXlXUxr",
        "outputId": "d42ce4f4-5d93-465f-a94a-49daa71a92ac"
      },
      "outputs": [],
      "source": [
        "# creating tables for rushing, passing, and receiving. merging the rushing\n",
        "# and passing dataframes because sometimes quarterbacks run!\n",
        "\n",
        "rush_df = get_rushing()\n",
        "rec_df = get_receiving()\n",
        "qbs = get_qb_pass()\n",
        "\n",
        "qb_df = qbs.merge(rush_df.drop(columns='success'), how='left', on=['game_id', 'player', 'player_id', 'team', 'total_line', 'home_team', 'away_team'])\n",
        "qb_df.fillna(0, inplace=True)\n",
        "qb_df['total_epa'] = qb_df['rush_epa'].add(qb_df['epa'])\n",
        "\n",
        "print(qb_df.shape)\n",
        "print(rec_df.shape)\n",
        "print(rush_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRZB6GesIGsR"
      },
      "outputs": [],
      "source": [
        "team_pass_yds = get_team_pass_yds()\n",
        "team_rush_yds = get_team_rush_yds()\n",
        "\n",
        "opp_rush = get_opp_rush()\n",
        "opp_pass = get_opp_pass()\n",
        "\n",
        "def_stats = get_def_stats()\n",
        "team_scores = get_team_scores()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgIGs3SPIu3o"
      },
      "outputs": [],
      "source": [
        "games_df = get_game_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiLpJFFSKGWF"
      },
      "outputs": [],
      "source": [
        "ref_rev_dict = create_ref_dict()\n",
        "games_df['referee'] = games_df['referee'].map(ref_rev_dict).fillna(games_df['referee'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7H52cw1HL-Y"
      },
      "outputs": [],
      "source": [
        "drive_stats = get_drive_stats()\n",
        "drive_summary = drive_stats.groupby(['game_id', 'team'], as_index=False).agg({'poss_time' : 'sum',\n",
        "                                                                              'rush_attempt' : 'sum',\n",
        "                                                                              'pass_attempt' : 'sum',\n",
        "                                                                              'total_plays' : 'sum'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zdbj0KNg4Vr"
      },
      "outputs": [],
      "source": [
        "games_df = games_df.merge(drive_summary, how='left', on=['game_id', 'team'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZU9rzRPDE3M"
      },
      "outputs": [],
      "source": [
        "games_df['pass_per_attempt'] = games_df['pass_yards'].div(games_df['pass_attempt']).round(1)\n",
        "games_df['perc_pass'] = games_df['pass_attempt'].div(games_df['total_plays']).round(3)\n",
        "games_df['sec_per_play'] = games_df['poss_time'].div(games_df['total_plays']).round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuJHpM4slpCD"
      },
      "outputs": [],
      "source": [
        "adj_epa = get_team_adjusted_epa()\n",
        "\n",
        "off_epa_game = (\n",
        "    adj_epa\n",
        "    .groupby(['game_id', 'posteam', 'play_type'], as_index=False)['epa']\n",
        "    .agg(['sum'])\n",
        "    .reset_index()\n",
        "    .pivot_table(index=['game_id', 'posteam'],\n",
        "                 columns='play_type',\n",
        "                 values='sum')\n",
        "    .reset_index()\n",
        "    .rename(columns={\n",
        "        'pass' : 'off_pass_epa',\n",
        "        'run' : 'off_run_epa',\n",
        "        'posteam' : 'team'\n",
        "    })\n",
        "    .round(2)\n",
        ")\n",
        "\n",
        "def_epa_game = (\n",
        "    adj_epa\n",
        "    .groupby(['game_id', 'defteam', 'play_type'], as_index=False)['epa']\n",
        "    .agg(['sum'])\n",
        "    .reset_index()\n",
        "    .pivot_table(index=['game_id', 'defteam'],\n",
        "                 columns='play_type',\n",
        "                 values='sum')\n",
        "    .reset_index()\n",
        "    .rename(columns={\n",
        "        'pass' : 'def_pass_epa',\n",
        "        'run' : 'def_run_epa',\n",
        "        'defteam' : 'team'\n",
        "    })\n",
        "    .round(2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-lMGSnYjsWa"
      },
      "outputs": [],
      "source": [
        "date_threshold = '2021-10-16'\n",
        "pbp_df = df[df['game_date'] >= date_threshold].copy()\n",
        "\n",
        "for chunk in np.array_split(pbp_df, 3):\n",
        "  df_ = pd.DataFrame(chunk)\n",
        "\n",
        "  insert_into_table(df_, 'pbp', URI)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
