{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nu-MfQlHpoRn",
    "outputId": "2b0733dc-feb3-4dcb-cd3c-abe86764be3e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from db_utils import create_table, populate_table, insert_into_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading up the postgres credentials\n",
    "user = os.environ['DB_USER']\n",
    "password = os.environ['DB_PASSWORD']\n",
    "host = os.environ['DB_HOST']\n",
    "database = os.environ['DB_NAME']\n",
    "port = os.environ['DB_PORT']\n",
    "    \n",
    "URI = f'postgresql://{user}:{password}@{host}:{port}/{database}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bI_dkD_JqY95",
    "outputId": "57bcfda7-0a1d-4d0a-f0dc-9e8505d2b178"
   },
   "outputs": [],
   "source": [
    "# getting the directory path\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "nfl_pbp_dir = 'data/pbp'\n",
    "nfl_depth_chart_dir = 'data/depth_charts'\n",
    "\n",
    "# loading all of the parquets files at once using the directory path\n",
    "# replacing backslashes with empty strings to avoid csv errors\n",
    "df = pd.read_parquet(f'{parent_dir}/{nfl_pbp_dir}')\n",
    "df['desc'] = df['desc'].str.replace('\\\\', '', regex=True)\n",
    "df['season'] = [int(x.split('_')[0]) for x in df.game_id]\n",
    "\n",
    "print(\"the shape of the pbp df is:\", df.shape)\n",
    "print(\"the memory usage of the pbp df is :\", df.memory_usage(deep=True).sum() / 1024**2, \"MB\")\n",
    "\n",
    "# dropping columns to reduce the memory required in the hopes of populating the db\n",
    "# all at once, but it didn't work. I'll have to do it in chunks.\n",
    "unneeded_cols = ['nfl_api_id', 'old_game_id', 'home_coach', 'away_coach', 'game_stadium', 'weather']\n",
    "df.drop(columns=[x for x in df.columns if 'lateral' in x], inplace=True)\n",
    "df.drop(columns=[x for x in df.columns if 'player_2' in x], inplace=True)\n",
    "df.drop(columns=[x for x in df.columns if 'total' in x], inplace=True)\n",
    "df.drop(columns=unneeded_cols, inplace=True)\n",
    "\n",
    "print(\"the memory usage of the pbp after dropping is :\", df.memory_usage(deep=True).sum() / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the pbp table\n",
    "create_table(df=df, table_name='pbp', URI=URI)\n",
    "\n",
    "# creating a subset of the pbp df to test the populate_table function\n",
    "testdf = df.iloc[:10000]\n",
    "populate_table(df=testdf, table_name='pbp', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the insert function to get the pbp  into the database\n",
    "# quickly - estimated time with 50k chunk sizes is 2.5 minutes\n",
    "# the print statements keep track of the progress and \n",
    "# enable error identification\n",
    "\n",
    "chunks = [x for x in range(10000, len(df), 50000)]\n",
    "\n",
    "for i in range(len(chunks)):\n",
    "    \n",
    "    if i < (len(chunks) - 1):\n",
    "        print(i)\n",
    "        df_ = df.iloc[chunks[i] : chunks[i+1]].copy()\n",
    "        print(\"chunk final index:\", df_.index[-1])\n",
    "        try:\n",
    "            insert_into_table(df=df_, table_name='pbp', URI=URI)\n",
    "        except:\n",
    "            print(\"error in insert\", i)\n",
    "            print(df_.index[-1])\n",
    "            continue\n",
    "    else:\n",
    "        print(i)\n",
    "        df_ = df.iloc[chunks[i]:].copy()\n",
    "        print(\"last chunk final index:\", df_.index[-1])\n",
    "        try:\n",
    "            insert_into_table(df=df_, table_name='pbp', URI=URI)\n",
    "        except:\n",
    "            print(\"error for some other reason\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and inserting the depth chart data into the database\n",
    "# depth chart df needed to have line breaks replaced\n",
    "\n",
    "depth_charts = pd.read_parquet(f'{parent_dir}/{nfl_depth_chart_dir}')\n",
    "depth_charts['depth_position'] = depth_charts['depth_position'].str.replace(\"\\n\", '')\n",
    "\n",
    "create_table(df=depth_charts, table_name='depth_charts', URI=URI)\n",
    "populate_table(df=depth_charts, table_name='depth_charts', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading player stats data into the database\n",
    "player_stats = pd.read_parquet(f'{parent_dir}/data/player_stats')\n",
    "\n",
    "create_table(df=player_stats, table_name='player_stats', URI=URI)\n",
    "populate_table(df=player_stats, table_name='player_stats', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading nextgen data into the database\n",
    "nextgen = pd.read_parquet(f'{parent_dir}/data/nextgen')\n",
    "\n",
    "create_table(df=nextgen, table_name='nextgen', URI=URI)\n",
    "populate_table(df=nextgen, table_name='nextgen', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading misc data into the database\n",
    "misc = pd.read_parquet(f'{parent_dir}/data/misc')\n",
    "\n",
    "create_table(df=misc, table_name='misc', URI=URI)\n",
    "populate_table(df=misc, table_name='misc', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading snap counts data into the database\n",
    "snaps = pd.read_parquet(f'{parent_dir}/data/snap_counts')\n",
    "\n",
    "create_table(df=snaps, table_name='snaps', URI=URI)\n",
    "populate_table(df=snaps, table_name='snaps', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aSC_e52GPwn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to the db..\n",
      "connected to the database..\n",
      "creating the cursor..\n",
      "writing the csv to file..\n",
      "data inserted into table successfully!\n"
     ]
    }
   ],
   "source": [
    "# loading Lee Sharpe's data into the database\n",
    "lee_sharpe = 'https://raw.githubusercontent.com/nflverse/nfldata/master/data/games.csv'\n",
    "\n",
    "ls = pd.read_csv(lee_sharpe)\n",
    "ls = ls.sort_values(by='game_id')\n",
    "\n",
    "create_table(df=ls, table_name='lee_sharpe', URI=URI)\n",
    "populate_table(df=ls, table_name='lee_sharpe', URI=URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_stat_query = \"\"\"\n",
    "    select \n",
    "        game_id,\n",
    "        home_team,\n",
    "        away_team,\n",
    "        sum(case when posteam = home_team and play_type_nfl = 'RUSH' then yards_gained else 0 end) as home_rush_yards,\n",
    "        sum(case when posteam = home_team and play_type_nfl = 'RUSH' then epa else 0 end) as home_rush_epa,\n",
    "        sum(case when posteam = home_team and play_type_nfl = 'PASS' then yards_gained else 0 end) as home_pass_yards,\n",
    "        sum(case when posteam = home_team and play_type_nfl = 'PASS' then epa else 0 end) as home_pass_epa,\n",
    "        sum(case when posteam = away_team and play_type_nfl = 'SACK' then 1 else 0 end) as home_team_sacks,\n",
    "        sum(case when posteam = away_team and play_type_nfl = 'RUSH' then yards_gained else 0 end) as away_rush_yards,\n",
    "        sum(case when posteam = away_team and play_type_nfl = 'RUSH' then epa else 0 end) as away_rush_epa,\n",
    "        sum(case when posteam = away_team and play_type_nfl = 'PASS' then yards_gained else 0 end) as away_pass_yards,\n",
    "        sum(case when posteam = away_team and play_type_nfl = 'PASS' then epa else 0 end) as away_pass_epa,\n",
    "        sum(case when posteam = home_team and play_type_nfl = 'SACK' then 1 else 0 end) as away_team_sacks\n",
    "    from pbp\n",
    "    where season >=2016\n",
    "    group by game_id, home_team, away_team\n",
    "    order by game_id asc\n",
    "\"\"\"\n",
    "\n",
    "game_stats = pd.read_sql(game_stat_query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to the db..\n",
      "connected to the database..\n",
      "creating the cursor..\n",
      "writing the csv to file..\n",
      "data inserted into table successfully!\n"
     ]
    }
   ],
   "source": [
    "# loading stadium locations into the database\n",
    "stadium_file = os.path.join(parent_dir, 'data', 'misc', 'stadium_locations_07_17.csv')\n",
    "\n",
    "stadium_df = pd.read_csv(stadium_file)\n",
    "\n",
    "create_table(df=stadium_df, table_name='stadium_locations', URI=URI)\n",
    "populate_table(df=stadium_df, table_name='stadium_locations', URI=URI)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
